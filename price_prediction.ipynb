{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a314bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>number_of_amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>107</td>\n",
       "      <td>38.8910</td>\n",
       "      <td>-77.0816</td>\n",
       "      <td>1577359410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>925</td>\n",
       "      <td>116</td>\n",
       "      <td>47.6160</td>\n",
       "      <td>-122.3275</td>\n",
       "      <td>1576667743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2475</td>\n",
       "      <td>130</td>\n",
       "      <td>40.7629</td>\n",
       "      <td>-73.9885</td>\n",
       "      <td>1577289784</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1495</td>\n",
       "      <td>138</td>\n",
       "      <td>37.7599</td>\n",
       "      <td>-122.4379</td>\n",
       "      <td>1577358313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1695</td>\n",
       "      <td>190</td>\n",
       "      <td>37.7599</td>\n",
       "      <td>-122.4379</td>\n",
       "      <td>1577015121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  price  square_feet  latitude  longitude        time  \\\n",
       "0        1.0       0.0   1390          107   38.8910   -77.0816  1577359410   \n",
       "1        1.0       0.0    925          116   47.6160  -122.3275  1576667743   \n",
       "2        1.0       0.0   2475          130   40.7629   -73.9885  1577289784   \n",
       "3        1.0       0.0   1495          138   37.7599  -122.4379  1577358313   \n",
       "4        1.0       0.0   1695          190   37.7599  -122.4379  1577015121   \n",
       "\n",
       "   number_of_amenities  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    5  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('apartments_for_rent_10k_numeric.csv', sep=',', header=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88022b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>number_of_amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9.950000e+03</td>\n",
       "      <td>9950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.380553</td>\n",
       "      <td>1.747538</td>\n",
       "      <td>1487.585930</td>\n",
       "      <td>943.271055</td>\n",
       "      <td>37.696104</td>\n",
       "      <td>-94.663883</td>\n",
       "      <td>1.574881e+09</td>\n",
       "      <td>3.125025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.615313</td>\n",
       "      <td>0.941543</td>\n",
       "      <td>1077.350394</td>\n",
       "      <td>526.416278</td>\n",
       "      <td>5.501219</td>\n",
       "      <td>15.760136</td>\n",
       "      <td>3.767608e+06</td>\n",
       "      <td>3.430139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>21.315500</td>\n",
       "      <td>-158.022100</td>\n",
       "      <td>1.568744e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>33.679500</td>\n",
       "      <td>-101.301700</td>\n",
       "      <td>1.568781e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>38.809600</td>\n",
       "      <td>-93.651600</td>\n",
       "      <td>1.577358e+09</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>41.349800</td>\n",
       "      <td>-82.302000</td>\n",
       "      <td>1.577359e+09</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>52500.000000</td>\n",
       "      <td>11318.000000</td>\n",
       "      <td>61.594000</td>\n",
       "      <td>-70.191600</td>\n",
       "      <td>1.577362e+09</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms     bedrooms         price   square_feet     latitude  \\\n",
       "count  9950.000000  9950.000000   9950.000000   9950.000000  9950.000000   \n",
       "mean      1.380553     1.747538   1487.585930    943.271055    37.696104   \n",
       "std       0.615313     0.941543   1077.350394    526.416278     5.501219   \n",
       "min       1.000000     0.000000    200.000000    107.000000    21.315500   \n",
       "25%       1.000000     1.000000    950.000000    650.000000    33.679500   \n",
       "50%       1.000000     2.000000   1275.000000    803.000000    38.809600   \n",
       "75%       2.000000     2.000000   1695.000000   1100.000000    41.349800   \n",
       "max       8.500000     9.000000  52500.000000  11318.000000    61.594000   \n",
       "\n",
       "         longitude          time  number_of_amenities  \n",
       "count  9950.000000  9.950000e+03          9950.000000  \n",
       "mean    -94.663883  1.574881e+09             3.125025  \n",
       "std      15.760136  3.767608e+06             3.430139  \n",
       "min    -158.022100  1.568744e+09             0.000000  \n",
       "25%    -101.301700  1.568781e+09             0.000000  \n",
       "50%     -93.651600  1.577358e+09             2.000000  \n",
       "75%     -82.302000  1.577359e+09             5.000000  \n",
       "max     -70.191600  1.577362e+09            18.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fa2cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extreme outliers that skew linear regression\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60629fb8",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3d8c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d751921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: $444.30\n",
      "Scaled X, Original Y - R²: 0.241\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['price'])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_log = np.log(df['price'])  # Log transform target\n",
    "\n",
    "# Test 1: Scaled X, original y (your best result so far)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['price'], test_size=0.2, random_state=42)\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: ${rmse:.2f}\")\n",
    "print(f\"Scaled X, Original Y - R²: {r2_score(y_test, y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cfd7e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: $257.49\n",
      "Scaled X, Original Y - R²: 0.745\n"
     ]
    }
   ],
   "source": [
    "# Before scaling, add these engineered features:\n",
    "df['price_per_sqft'] = df['price'] / df['square_feet']\n",
    "df['rooms_per_sqft'] = (df['bedrooms'] + df['bathrooms']) / df['square_feet']\n",
    "\n",
    "X = df.drop(columns=['price'])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_log = np.log(df['price'])  # Log transform target\n",
    "\n",
    "# Test 1: Scaled X, original y (your best result so far)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['price'], test_size=0.2, random_state=42)\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: ${rmse:.2f}\")\n",
    "print(f\"Scaled X, Original Y - R²: {r2_score(y_test, y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d7654",
   "metadata": {},
   "source": [
    "MLP (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "58c9a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rkaya\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer (no activation for regression)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d0ab60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09f5da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1939153.1250 - mae: 1300.1273 - val_loss: 1689534.0000 - val_mae: 1211.2450\n",
      "Epoch 2/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1488706.6250 - mae: 1121.6720 - val_loss: 679155.5625 - val_mae: 710.1139\n",
      "Epoch 3/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 514746.6562 - mae: 586.3233 - val_loss: 236174.2656 - val_mae: 350.7606\n",
      "Epoch 4/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217929.2344 - mae: 341.3410 - val_loss: 188757.4688 - val_mae: 296.0337\n",
      "Epoch 5/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 171402.4062 - mae: 298.6752 - val_loss: 159631.0469 - val_mae: 262.7397\n",
      "Epoch 6/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144471.8594 - mae: 274.1495 - val_loss: 139042.8438 - val_mae: 233.2829\n",
      "Epoch 7/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117278.5000 - mae: 242.2954 - val_loss: 122868.7344 - val_mae: 208.2324\n",
      "Epoch 8/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103879.3359 - mae: 225.3423 - val_loss: 112831.1328 - val_mae: 189.1519\n",
      "Epoch 9/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 91864.3672 - mae: 210.0560 - val_loss: 105905.4531 - val_mae: 175.5360\n",
      "Epoch 10/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78667.7578 - mae: 193.1954 - val_loss: 101137.9297 - val_mae: 165.8003\n",
      "Epoch 11/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68604.8906 - mae: 182.6490 - val_loss: 99946.3359 - val_mae: 156.9031\n",
      "Epoch 12/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70204.0000 - mae: 180.2865 - val_loss: 99169.0781 - val_mae: 150.7443\n",
      "Epoch 13/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64354.6641 - mae: 173.5224 - val_loss: 94895.2188 - val_mae: 148.3890\n",
      "Epoch 14/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64062.2148 - mae: 171.9225 - val_loss: 93234.5312 - val_mae: 144.3538\n",
      "Epoch 15/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57437.6211 - mae: 164.1865 - val_loss: 92170.3594 - val_mae: 142.1485\n",
      "Epoch 16/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61436.6914 - mae: 168.4068 - val_loss: 90412.8750 - val_mae: 140.5053\n",
      "Epoch 17/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54146.5664 - mae: 158.5633 - val_loss: 87544.6250 - val_mae: 141.9357\n",
      "Epoch 18/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59832.6328 - mae: 166.7420 - val_loss: 86873.2891 - val_mae: 139.9359\n",
      "Epoch 19/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54462.6836 - mae: 156.8289 - val_loss: 86027.4453 - val_mae: 138.6149\n",
      "Epoch 20/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52829.2695 - mae: 158.8134 - val_loss: 86190.7188 - val_mae: 134.6506\n",
      "Epoch 21/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51599.3086 - mae: 151.9259 - val_loss: 84886.5469 - val_mae: 135.4165\n",
      "Epoch 22/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62264.0742 - mae: 162.9747 - val_loss: 83587.4375 - val_mae: 134.7461\n",
      "Epoch 23/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52430.8164 - mae: 153.4302 - val_loss: 84831.5391 - val_mae: 132.4986\n",
      "Epoch 24/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52186.7109 - mae: 153.7350 - val_loss: 83797.3906 - val_mae: 132.7426\n",
      "Epoch 25/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50713.7812 - mae: 152.4913 - val_loss: 83159.3828 - val_mae: 133.6694\n",
      "Epoch 26/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55650.3242 - mae: 155.2481 - val_loss: 84026.9766 - val_mae: 130.4874\n",
      "Epoch 27/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51868.8594 - mae: 151.4551 - val_loss: 84220.2734 - val_mae: 129.2241\n",
      "Epoch 28/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53196.1797 - mae: 154.7098 - val_loss: 83405.7266 - val_mae: 128.3943\n",
      "Epoch 29/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51586.9375 - mae: 150.8294 - val_loss: 82760.2188 - val_mae: 129.0198\n",
      "Epoch 30/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52912.1680 - mae: 151.0533 - val_loss: 80868.2500 - val_mae: 130.8966\n",
      "Epoch 31/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53317.1641 - mae: 153.1440 - val_loss: 81372.0469 - val_mae: 127.7700\n",
      "Epoch 32/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52814.2188 - mae: 151.7670 - val_loss: 81788.1094 - val_mae: 128.2032\n",
      "Epoch 33/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51001.6289 - mae: 151.1001 - val_loss: 80187.6875 - val_mae: 127.6572\n",
      "Epoch 34/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51606.7891 - mae: 152.1958 - val_loss: 81154.3203 - val_mae: 128.5538\n",
      "Epoch 35/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50937.3828 - mae: 150.1178 - val_loss: 82974.5781 - val_mae: 127.2250\n",
      "Epoch 36/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51890.3398 - mae: 147.9651 - val_loss: 80008.1953 - val_mae: 127.4290\n",
      "Epoch 37/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55823.1211 - mae: 154.0720 - val_loss: 81303.4453 - val_mae: 125.5722\n",
      "Epoch 38/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52235.4805 - mae: 151.7239 - val_loss: 81923.6484 - val_mae: 124.5404\n",
      "Epoch 39/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50847.6211 - mae: 148.2245 - val_loss: 80197.7266 - val_mae: 126.2555\n",
      "Epoch 40/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47001.9570 - mae: 144.1119 - val_loss: 80132.4531 - val_mae: 125.7807\n",
      "Epoch 41/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52386.3359 - mae: 150.9867 - val_loss: 79862.7734 - val_mae: 126.1321\n",
      "Epoch 42/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50533.5039 - mae: 148.5743 - val_loss: 79065.1328 - val_mae: 125.6034\n",
      "Epoch 43/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49033.6523 - mae: 146.3425 - val_loss: 78824.7422 - val_mae: 127.3470\n",
      "Epoch 44/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48204.3594 - mae: 145.2525 - val_loss: 79293.2344 - val_mae: 124.8619\n",
      "Epoch 45/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52418.3320 - mae: 148.9990 - val_loss: 79545.2812 - val_mae: 124.4053\n",
      "Epoch 46/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48256.3164 - mae: 146.0346 - val_loss: 79112.3828 - val_mae: 124.9587\n",
      "Epoch 47/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49002.7422 - mae: 147.2213 - val_loss: 78109.2188 - val_mae: 125.4925\n",
      "Epoch 48/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50010.5938 - mae: 146.5197 - val_loss: 77655.1719 - val_mae: 127.2647\n",
      "Epoch 49/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50563.5469 - mae: 150.0573 - val_loss: 79160.9219 - val_mae: 124.3044\n",
      "Epoch 50/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50442.8086 - mae: 145.8701 - val_loss: 77838.8438 - val_mae: 125.9030\n",
      "Epoch 51/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47677.8555 - mae: 145.3415 - val_loss: 78130.9375 - val_mae: 123.9314\n",
      "Epoch 52/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48293.3320 - mae: 144.7359 - val_loss: 79359.4531 - val_mae: 123.3518\n",
      "Epoch 53/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48787.7031 - mae: 144.8100 - val_loss: 77016.6250 - val_mae: 124.0147\n",
      "Epoch 54/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49634.4844 - mae: 145.2907 - val_loss: 77250.8672 - val_mae: 123.7976\n",
      "Epoch 55/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47940.9805 - mae: 145.5496 - val_loss: 76496.1641 - val_mae: 123.6730\n",
      "Epoch 56/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48700.9531 - mae: 144.3007 - val_loss: 76365.9766 - val_mae: 123.6899\n",
      "Epoch 57/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46869.3516 - mae: 144.0144 - val_loss: 77176.7188 - val_mae: 121.9728\n",
      "Epoch 58/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47690.0742 - mae: 144.3729 - val_loss: 76138.4141 - val_mae: 122.4896\n",
      "Epoch 59/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45757.2539 - mae: 142.2198 - val_loss: 74746.2969 - val_mae: 125.9904\n",
      "Epoch 60/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48202.9219 - mae: 147.0968 - val_loss: 75384.6875 - val_mae: 121.7651\n",
      "Epoch 61/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49610.2852 - mae: 146.0794 - val_loss: 73869.1641 - val_mae: 125.1741\n",
      "Epoch 62/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50003.6367 - mae: 146.2794 - val_loss: 74665.6719 - val_mae: 120.9247\n",
      "Epoch 63/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46606.5391 - mae: 143.6598 - val_loss: 74327.8125 - val_mae: 120.7696\n",
      "Epoch 64/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45632.9492 - mae: 141.8566 - val_loss: 73498.6562 - val_mae: 123.0489\n",
      "Epoch 65/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46298.2148 - mae: 144.4139 - val_loss: 75289.7656 - val_mae: 119.2902\n",
      "Epoch 66/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48045.8867 - mae: 143.4400 - val_loss: 74533.3672 - val_mae: 118.3380\n",
      "Epoch 67/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44311.3711 - mae: 141.2237 - val_loss: 72988.8672 - val_mae: 120.4068\n",
      "Epoch 68/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49837.9219 - mae: 145.7601 - val_loss: 74271.4062 - val_mae: 117.5584\n",
      "Epoch 69/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45962.8125 - mae: 140.3843 - val_loss: 72671.3281 - val_mae: 118.2050\n",
      "Epoch 70/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45484.7305 - mae: 141.3328 - val_loss: 73389.5703 - val_mae: 114.9440\n",
      "Epoch 71/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 41097.4883 - mae: 136.4727 - val_loss: 71333.5391 - val_mae: 114.2991\n",
      "Epoch 72/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42073.1094 - mae: 135.7401 - val_loss: 71041.0391 - val_mae: 112.4687\n",
      "Epoch 73/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43399.9766 - mae: 136.6385 - val_loss: 70509.8359 - val_mae: 110.5805\n",
      "Epoch 74/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38943.6562 - mae: 131.3177 - val_loss: 68519.8359 - val_mae: 110.3280\n",
      "Epoch 75/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40244.8516 - mae: 132.9266 - val_loss: 68029.3203 - val_mae: 107.0333\n",
      "Epoch 76/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38677.6484 - mae: 130.1831 - val_loss: 65779.1406 - val_mae: 106.4297\n",
      "Epoch 77/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37618.3047 - mae: 130.3959 - val_loss: 65223.0508 - val_mae: 104.8010\n",
      "Epoch 78/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39040.6484 - mae: 130.2744 - val_loss: 62144.5234 - val_mae: 101.6401\n",
      "Epoch 79/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36417.2109 - mae: 129.0454 - val_loss: 61193.2422 - val_mae: 99.2550\n",
      "Epoch 80/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34175.2188 - mae: 121.8249 - val_loss: 59143.4688 - val_mae: 96.2616\n",
      "Epoch 81/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32494.6660 - mae: 120.5530 - val_loss: 58835.4648 - val_mae: 93.1362\n",
      "Epoch 82/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34709.2344 - mae: 122.2197 - val_loss: 56704.5586 - val_mae: 91.2401\n",
      "Epoch 83/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30979.9414 - mae: 117.1998 - val_loss: 53880.8633 - val_mae: 88.9431\n",
      "Epoch 84/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30393.4648 - mae: 116.7789 - val_loss: 54455.3750 - val_mae: 84.8314\n",
      "Epoch 85/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29337.7676 - mae: 114.4595 - val_loss: 51361.2109 - val_mae: 83.2879\n",
      "Epoch 86/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28826.0332 - mae: 114.1177 - val_loss: 49909.0000 - val_mae: 81.1162\n",
      "Epoch 87/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25617.6055 - mae: 109.2742 - val_loss: 46795.3984 - val_mae: 80.6940\n",
      "Epoch 88/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26829.1602 - mae: 110.2799 - val_loss: 44241.3320 - val_mae: 79.0818\n",
      "Epoch 89/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25234.5586 - mae: 106.3028 - val_loss: 43607.7500 - val_mae: 75.7445\n",
      "Epoch 90/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24742.4141 - mae: 104.4342 - val_loss: 43478.1602 - val_mae: 75.2359\n",
      "Epoch 91/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24094.7832 - mae: 105.2826 - val_loss: 40770.2773 - val_mae: 71.8266\n",
      "Epoch 92/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24138.7246 - mae: 105.9216 - val_loss: 39813.8242 - val_mae: 69.4580\n",
      "Epoch 93/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22035.4746 - mae: 102.8316 - val_loss: 39606.6992 - val_mae: 68.3136\n",
      "Epoch 94/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18963.2031 - mae: 96.6357 - val_loss: 37868.2578 - val_mae: 67.2401\n",
      "Epoch 95/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20708.2461 - mae: 99.6788 - val_loss: 37501.4688 - val_mae: 66.2435\n",
      "Epoch 96/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18668.1367 - mae: 96.1884 - val_loss: 35915.8047 - val_mae: 65.5073\n",
      "Epoch 97/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18522.0723 - mae: 95.1205 - val_loss: 35790.7266 - val_mae: 63.1605\n",
      "Epoch 98/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16960.5234 - mae: 92.5898 - val_loss: 32747.8633 - val_mae: 63.9478\n",
      "Epoch 99/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18354.6406 - mae: 94.8259 - val_loss: 33513.7070 - val_mae: 60.5867\n",
      "Epoch 100/100\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17549.1328 - mae: 93.4805 - val_loss: 33743.7852 - val_mae: 58.5231\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b87efb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Neural Network RMSE: $128.83\n",
      "Neural Network R²: 0.936\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Neural Network RMSE: ${rmse:.2f}\")\n",
    "print(f\"Neural Network R²: {r2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
