{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a314bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>number_of_amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>107</td>\n",
       "      <td>38.8910</td>\n",
       "      <td>-77.0816</td>\n",
       "      <td>1577359410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>925</td>\n",
       "      <td>116</td>\n",
       "      <td>47.6160</td>\n",
       "      <td>-122.3275</td>\n",
       "      <td>1576667743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2475</td>\n",
       "      <td>130</td>\n",
       "      <td>40.7629</td>\n",
       "      <td>-73.9885</td>\n",
       "      <td>1577289784</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1495</td>\n",
       "      <td>138</td>\n",
       "      <td>37.7599</td>\n",
       "      <td>-122.4379</td>\n",
       "      <td>1577358313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1695</td>\n",
       "      <td>190</td>\n",
       "      <td>37.7599</td>\n",
       "      <td>-122.4379</td>\n",
       "      <td>1577015121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  price  square_feet  latitude  longitude        time  \\\n",
       "0        1.0       0.0   1390          107   38.8910   -77.0816  1577359410   \n",
       "1        1.0       0.0    925          116   47.6160  -122.3275  1576667743   \n",
       "2        1.0       0.0   2475          130   40.7629   -73.9885  1577289784   \n",
       "3        1.0       0.0   1495          138   37.7599  -122.4379  1577358313   \n",
       "4        1.0       0.0   1695          190   37.7599  -122.4379  1577015121   \n",
       "\n",
       "   number_of_amenities  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    5  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('apartments_for_rent_10k_numeric.csv', sep=',', header=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88022b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>number_of_amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9950.000000</td>\n",
       "      <td>9.950000e+03</td>\n",
       "      <td>9950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.380553</td>\n",
       "      <td>1.747538</td>\n",
       "      <td>1487.585930</td>\n",
       "      <td>943.271055</td>\n",
       "      <td>37.696104</td>\n",
       "      <td>-94.663883</td>\n",
       "      <td>1.574881e+09</td>\n",
       "      <td>3.125025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.615313</td>\n",
       "      <td>0.941543</td>\n",
       "      <td>1077.350394</td>\n",
       "      <td>526.416278</td>\n",
       "      <td>5.501219</td>\n",
       "      <td>15.760136</td>\n",
       "      <td>3.767608e+06</td>\n",
       "      <td>3.430139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>21.315500</td>\n",
       "      <td>-158.022100</td>\n",
       "      <td>1.568744e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>33.679500</td>\n",
       "      <td>-101.301700</td>\n",
       "      <td>1.568781e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>38.809600</td>\n",
       "      <td>-93.651600</td>\n",
       "      <td>1.577358e+09</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>41.349800</td>\n",
       "      <td>-82.302000</td>\n",
       "      <td>1.577359e+09</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>52500.000000</td>\n",
       "      <td>11318.000000</td>\n",
       "      <td>61.594000</td>\n",
       "      <td>-70.191600</td>\n",
       "      <td>1.577362e+09</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms     bedrooms         price   square_feet     latitude  \\\n",
       "count  9950.000000  9950.000000   9950.000000   9950.000000  9950.000000   \n",
       "mean      1.380553     1.747538   1487.585930    943.271055    37.696104   \n",
       "std       0.615313     0.941543   1077.350394    526.416278     5.501219   \n",
       "min       1.000000     0.000000    200.000000    107.000000    21.315500   \n",
       "25%       1.000000     1.000000    950.000000    650.000000    33.679500   \n",
       "50%       1.000000     2.000000   1275.000000    803.000000    38.809600   \n",
       "75%       2.000000     2.000000   1695.000000   1100.000000    41.349800   \n",
       "max       8.500000     9.000000  52500.000000  11318.000000    61.594000   \n",
       "\n",
       "         longitude          time  number_of_amenities  \n",
       "count  9950.000000  9.950000e+03          9950.000000  \n",
       "mean    -94.663883  1.574881e+09             3.125025  \n",
       "std      15.760136  3.767608e+06             3.430139  \n",
       "min    -158.022100  1.568744e+09             0.000000  \n",
       "25%    -101.301700  1.568781e+09             0.000000  \n",
       "50%     -93.651600  1.577358e+09             2.000000  \n",
       "75%     -82.302000  1.577359e+09             5.000000  \n",
       "max     -70.191600  1.577362e+09            18.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa2cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extreme outliers that skew linear regression\n",
    "# Q1 = df['price'].quantile(0.25)\n",
    "# Q3 = df['price'].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# df = df[~((df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60629fb8",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d8c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d751921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: $750.53\n",
      "Scaled X, Original Y - R²: 0.322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['price'])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_log = np.log(df['price'])  # Log transform target\n",
    "\n",
    "# Test 1: Scaled X, original y (your best result so far)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['price'], test_size=0.2, random_state=42)\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: ${rmse:.2f}\")\n",
    "print(f\"Scaled X, Original Y - R²: {r2_score(y_test, y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfd7e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: $751.92\n",
      "Scaled X, Original Y - R²: 0.320\n"
     ]
    }
   ],
   "source": [
    "# # Before scaling, add these engineered features:\n",
    "# df['price_per_sqft'] = df['price'] / df['square_feet']\n",
    "df['rooms_per_sqft'] = (df['bedrooms'] + df['bathrooms']) / df['square_feet']\n",
    "\n",
    "X = df.drop(columns=['price'])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_log = np.log(df['price'])  # Log transform target\n",
    "\n",
    "# Test 1: Scaled X, original y (your best result so far)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['price'], test_size=0.2, random_state=42)\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: ${rmse:.2f}\")\n",
    "print(f\"Scaled X, Original Y - R²: {r2_score(y_test, y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d7654",
   "metadata": {},
   "source": [
    "MLP (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58c9a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rkaya\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer (no activation for regression)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0ab60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09f5da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3474591.0000 - mae: 1489.2770 - val_loss: 3174976.7500 - val_mae: 1444.1996\n",
      "Epoch 2/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3095986.2500 - mae: 1376.8364 - val_loss: 2092044.2500 - val_mae: 1089.7764\n",
      "Epoch 3/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2614365.0000 - mae: 935.2024 - val_loss: 947539.1875 - val_mae: 585.0547\n",
      "Epoch 4/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1795685.5000 - mae: 560.5655 - val_loss: 717016.3125 - val_mae: 510.0309\n",
      "Epoch 5/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 803869.0000 - mae: 522.6229 - val_loss: 677182.8750 - val_mae: 501.0307\n",
      "Epoch 6/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1128850.6250 - mae: 519.0213 - val_loss: 670626.8750 - val_mae: 491.2245\n",
      "Epoch 7/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 782249.5000 - mae: 496.0111 - val_loss: 651913.7500 - val_mae: 492.2646\n",
      "Epoch 8/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 871801.3750 - mae: 507.1744 - val_loss: 647163.6875 - val_mae: 485.9582\n",
      "Epoch 9/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 596916.7500 - mae: 484.8458 - val_loss: 640458.5000 - val_mae: 480.7197\n",
      "Epoch 10/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1498975.0000 - mae: 517.7412 - val_loss: 638260.0625 - val_mae: 475.2111\n",
      "Epoch 11/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 794309.5625 - mae: 484.0031 - val_loss: 628115.6875 - val_mae: 475.4696\n",
      "Epoch 12/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 915419.7500 - mae: 479.2932 - val_loss: 624661.3750 - val_mae: 471.9782\n",
      "Epoch 13/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 1344549.7500 - mae: 493.7627 - val_loss: 615131.5625 - val_mae: 471.8154\n",
      "Epoch 14/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2406036.7500 - mae: 517.7538 - val_loss: 610311.1875 - val_mae: 468.9486\n",
      "Epoch 15/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 674452.8750 - mae: 489.0494 - val_loss: 607281.0625 - val_mae: 468.4242\n",
      "Epoch 16/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 536163.0000 - mae: 472.1016 - val_loss: 598911.1250 - val_mae: 470.7106\n",
      "Epoch 17/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 788169.5000 - mae: 476.9378 - val_loss: 596192.8750 - val_mae: 463.8734\n",
      "Epoch 18/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 774119.2500 - mae: 482.2010 - val_loss: 598878.3750 - val_mae: 454.0336\n",
      "Epoch 19/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 675214.5000 - mae: 464.5628 - val_loss: 591821.5000 - val_mae: 456.1700\n",
      "Epoch 20/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1016712.5000 - mae: 480.8174 - val_loss: 591971.5625 - val_mae: 449.1897\n",
      "Epoch 21/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 996077.0625 - mae: 453.2498 - val_loss: 581319.2500 - val_mae: 453.2809\n",
      "Epoch 22/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2111752.7500 - mae: 498.3103 - val_loss: 583128.9375 - val_mae: 444.7065\n",
      "Epoch 23/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 892637.0625 - mae: 464.9973 - val_loss: 576876.5625 - val_mae: 442.7851\n",
      "Epoch 24/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1543190.0000 - mae: 487.0605 - val_loss: 570890.4375 - val_mae: 441.9837\n",
      "Epoch 25/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 985239.7500 - mae: 458.0766 - val_loss: 565529.5625 - val_mae: 443.0877\n",
      "Epoch 26/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1447871.3750 - mae: 481.7941 - val_loss: 567409.3125 - val_mae: 435.4713\n",
      "Epoch 27/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1850856.3750 - mae: 478.9595 - val_loss: 560920.8125 - val_mae: 436.0814\n",
      "Epoch 28/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1029880.0000 - mae: 453.5831 - val_loss: 555684.0000 - val_mae: 436.5629\n",
      "Epoch 29/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 639761.6875 - mae: 452.4143 - val_loss: 552104.5625 - val_mae: 437.2914\n",
      "Epoch 30/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2755946.2500 - mae: 488.8395 - val_loss: 549979.1250 - val_mae: 433.7808\n",
      "Epoch 31/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 752385.5000 - mae: 448.5771 - val_loss: 545687.0000 - val_mae: 433.2564\n",
      "Epoch 32/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 549989.6875 - mae: 437.2082 - val_loss: 540568.3125 - val_mae: 437.5388\n",
      "Epoch 33/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 711326.0625 - mae: 448.9429 - val_loss: 540468.2500 - val_mae: 432.3369\n",
      "Epoch 34/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 568921.7500 - mae: 443.1297 - val_loss: 539595.7500 - val_mae: 430.2647\n",
      "Epoch 35/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 617226.2500 - mae: 448.6584 - val_loss: 538471.1250 - val_mae: 429.2901\n",
      "Epoch 36/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 735262.0000 - mae: 455.5237 - val_loss: 537278.5625 - val_mae: 426.5804\n",
      "Epoch 37/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1201276.6250 - mae: 440.6701 - val_loss: 535197.9375 - val_mae: 424.4821\n",
      "Epoch 38/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1713415.8750 - mae: 443.8139 - val_loss: 533688.0625 - val_mae: 423.2917\n",
      "Epoch 39/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 985605.6875 - mae: 455.9310 - val_loss: 532932.3750 - val_mae: 422.1200\n",
      "Epoch 40/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 740101.0000 - mae: 434.5268 - val_loss: 530419.7500 - val_mae: 421.4224\n",
      "Epoch 41/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 872415.4375 - mae: 444.5656 - val_loss: 527374.0000 - val_mae: 421.5340\n",
      "Epoch 42/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 457307.8438 - mae: 415.2195 - val_loss: 524614.4375 - val_mae: 424.2387\n",
      "Epoch 43/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 1326666.1250 - mae: 457.4621 - val_loss: 527712.8750 - val_mae: 418.6912\n",
      "Epoch 44/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 694694.8125 - mae: 429.9154 - val_loss: 520786.6875 - val_mae: 424.4318\n",
      "Epoch 45/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 961076.0625 - mae: 444.8664 - val_loss: 521424.1562 - val_mae: 420.8842\n",
      "Epoch 46/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1024214.3750 - mae: 444.5995 - val_loss: 527985.7500 - val_mae: 414.8541\n",
      "Epoch 47/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1221456.1250 - mae: 448.3503 - val_loss: 525747.5625 - val_mae: 415.7494\n",
      "Epoch 48/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 473353.3438 - mae: 424.7726 - val_loss: 517779.5000 - val_mae: 420.4212\n",
      "Epoch 49/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 566461.7500 - mae: 427.9976 - val_loss: 519708.7188 - val_mae: 418.6873\n",
      "Epoch 50/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 660811.2500 - mae: 434.8347 - val_loss: 518835.4688 - val_mae: 417.1478\n",
      "Epoch 51/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 642953.2500 - mae: 441.2707 - val_loss: 519869.6250 - val_mae: 416.2744\n",
      "Epoch 52/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 844949.9375 - mae: 433.0065 - val_loss: 517572.9062 - val_mae: 416.2416\n",
      "Epoch 53/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 560510.5000 - mae: 418.8143 - val_loss: 514401.2500 - val_mae: 420.3672\n",
      "Epoch 54/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1148184.1250 - mae: 441.7396 - val_loss: 516869.7188 - val_mae: 414.4396\n",
      "Epoch 55/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 682469.7500 - mae: 427.4727 - val_loss: 516610.2188 - val_mae: 413.6825\n",
      "Epoch 56/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1037756.1250 - mae: 453.2817 - val_loss: 516319.3125 - val_mae: 414.2944\n",
      "Epoch 57/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 764221.1875 - mae: 432.7884 - val_loss: 515419.8438 - val_mae: 413.5107\n",
      "Epoch 58/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 630737.2500 - mae: 418.4918 - val_loss: 512316.9062 - val_mae: 416.2595\n",
      "Epoch 59/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 442461.5312 - mae: 425.8560 - val_loss: 514031.1562 - val_mae: 412.6942\n",
      "Epoch 60/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 652148.6875 - mae: 442.0400 - val_loss: 510780.0625 - val_mae: 414.5760\n",
      "Epoch 61/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 850491.1875 - mae: 423.5630 - val_loss: 510876.6250 - val_mae: 413.1092\n",
      "Epoch 62/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 857975.2500 - mae: 428.7480 - val_loss: 510969.9375 - val_mae: 413.2437\n",
      "Epoch 63/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 716048.1875 - mae: 433.5920 - val_loss: 507317.4375 - val_mae: 415.6855\n",
      "Epoch 64/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 729948.1875 - mae: 429.3083 - val_loss: 509216.5625 - val_mae: 413.6408\n",
      "Epoch 65/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 791968.1875 - mae: 431.8059 - val_loss: 509030.9688 - val_mae: 412.4095\n",
      "Epoch 66/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 936368.7500 - mae: 438.7929 - val_loss: 508059.9062 - val_mae: 412.5399\n",
      "Epoch 67/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1246928.0000 - mae: 443.2089 - val_loss: 512396.8125 - val_mae: 408.5184\n",
      "Epoch 68/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1249621.8750 - mae: 428.4039 - val_loss: 506958.9688 - val_mae: 411.9137\n",
      "Epoch 69/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 815666.5625 - mae: 423.6952 - val_loss: 503775.3125 - val_mae: 414.3409\n",
      "Epoch 70/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 528458.4375 - mae: 436.5418 - val_loss: 503070.7188 - val_mae: 415.4088\n",
      "Epoch 71/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1037428.4375 - mae: 441.4783 - val_loss: 503755.2500 - val_mae: 412.3142\n",
      "Epoch 72/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 909168.2500 - mae: 444.5074 - val_loss: 503180.2500 - val_mae: 411.6992\n",
      "Epoch 73/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 546405.9375 - mae: 427.3251 - val_loss: 503261.3125 - val_mae: 412.4159\n",
      "Epoch 74/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 900513.4375 - mae: 429.1740 - val_loss: 503176.5312 - val_mae: 411.1029\n",
      "Epoch 75/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 669138.1250 - mae: 434.2314 - val_loss: 503801.5625 - val_mae: 410.0307\n",
      "Epoch 76/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 592354.3750 - mae: 423.2401 - val_loss: 501231.6875 - val_mae: 412.0022\n",
      "Epoch 77/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 697783.1875 - mae: 420.9615 - val_loss: 497138.0625 - val_mae: 415.8441\n",
      "Epoch 78/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 982176.1875 - mae: 432.1962 - val_loss: 501883.8438 - val_mae: 409.6279\n",
      "Epoch 79/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 908138.8750 - mae: 428.5374 - val_loss: 499971.4062 - val_mae: 409.5228\n",
      "Epoch 80/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2698072.5000 - mae: 455.9378 - val_loss: 501612.4375 - val_mae: 409.4423\n",
      "Epoch 81/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 541948.0000 - mae: 417.0380 - val_loss: 497893.9375 - val_mae: 411.5113\n",
      "Epoch 82/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 930735.0625 - mae: 450.3278 - val_loss: 497926.4062 - val_mae: 409.9530\n",
      "Epoch 83/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 626367.1875 - mae: 423.1594 - val_loss: 498501.8438 - val_mae: 408.5797\n",
      "Epoch 84/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 2000093.0000 - mae: 456.0863 - val_loss: 499056.2500 - val_mae: 408.0819\n",
      "Epoch 85/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 781970.0000 - mae: 416.1594 - val_loss: 494781.8750 - val_mae: 411.8158\n",
      "Epoch 86/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 565013.3125 - mae: 421.9595 - val_loss: 492969.1562 - val_mae: 414.3231\n",
      "Epoch 87/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 642378.1250 - mae: 425.9187 - val_loss: 492784.1250 - val_mae: 411.7852\n",
      "Epoch 88/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 519100.0000 - mae: 425.2211 - val_loss: 494097.9688 - val_mae: 411.5844\n",
      "Epoch 89/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1138169.7500 - mae: 434.1916 - val_loss: 495551.3438 - val_mae: 406.9818\n",
      "Epoch 90/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 918265.8750 - mae: 433.3900 - val_loss: 494853.3438 - val_mae: 408.3802\n",
      "Epoch 91/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 760958.9375 - mae: 432.9403 - val_loss: 494113.2500 - val_mae: 407.1550\n",
      "Epoch 92/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 501141.0000 - mae: 428.7048 - val_loss: 494059.9062 - val_mae: 406.6191\n",
      "Epoch 93/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 1690263.6250 - mae: 452.5967 - val_loss: 496703.9688 - val_mae: 406.8706\n",
      "Epoch 94/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 504922.3750 - mae: 421.8258 - val_loss: 490428.1562 - val_mae: 412.9330\n",
      "Epoch 95/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 466928.8750 - mae: 420.1976 - val_loss: 493105.0938 - val_mae: 408.8017\n",
      "Epoch 96/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 587936.9375 - mae: 425.3148 - val_loss: 491981.8438 - val_mae: 409.1348\n",
      "Epoch 97/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491327.2812 - mae: 417.5300 - val_loss: 486215.0625 - val_mae: 418.7801\n",
      "Epoch 98/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1596058.1250 - mae: 441.5256 - val_loss: 490402.8125 - val_mae: 406.4088\n",
      "Epoch 99/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1095501.1250 - mae: 444.2241 - val_loss: 491980.5312 - val_mae: 405.3422\n",
      "Epoch 100/100\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1075947.3750 - mae: 413.8394 - val_loss: 488316.2188 - val_mae: 407.2308\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b87efb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Neural Network RMSE: $648.19\n",
      "Neural Network R²: 0.494\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Neural Network RMSE: ${rmse:.2f}\")\n",
    "print(f\"Neural Network R²: {r2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
